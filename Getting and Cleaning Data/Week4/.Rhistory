)
tidy.full             <- aggregate(subjects.full[, 3:68], grouping, mean, na.rm = TRUE)
## Give tidy column names
for (i in 3:68)
{
colnames(tidy.full)[i] <- paste("Average by Subject and Activity ", colnames(tidy.full)[i])
}
trim.subjects.x   <- subjects.x[, mean.std.cols]
## Name columns based on their column names from subjects.x
colnames(trim.subjects.x) <- colnames(subjects.x)[mean.std.cols]
## Merge subjects.y and activities by ActivityID, make sure to not sort the data
## or we will have the wrong activities with the wrong subjects!!!
## To do this we add an id column temporarily
subjects.y$id         <- 1:nrow(subjects.y)
tidy.subjects.y       <- merge(subjects.y, activities, by = 'ActivityID', sort = FALSE)
tidy.subjects.y       <- tidy.subjects.y[order(tidy.subjects.y$id), ]
tidy.subjects.y       <- data.frame(tidy.subjects.y[, 3])
colnames(tidy.subjects.y)[1] <- 'Activity'
## Make one big data frame
subjects.full         <- cbind(subjects, tidy.subjects.y, trim.subjects.x)
## Get the average of each datapoint for each subject and activity pair
grouping              <- list(
Subject = subjects.full$Subject
,Activity = subjects.full$Activity
)
new.tidy.full             <- aggregate(subjects.full[, 3:68], grouping, mean, na.rm = TRUE)
## Give tidy column names
for (i in 3:68)
{
colnames(new.tidy.full)[i] <- paste("Average by Subject and Activity ", colnames(new.tidy.full)[i])
}
identical(new.tidy.full, tidy.full)
new.tidy.full
View(tidy.full)
View(new.tidy.full)
old.column.names      <- colnames(tidy.full)[-c('Activity', 'Subject')]
old.column.names      <- colnames(tidy.full)[,-c('Activity', 'Subject')]
old.column.names      <- colnames(tidy.full)[c('-Activity', '-Subject')]
old.column.names
old.column.names      <- colnames(tidy.full)[]
old.column.names
old.column.names      <- colnames(tidy.full)tidy.full[c('-Activity', '-Subject')]
colnames(tidy.full)
?colnames
colnames(subjects.x)[mean.std.cols]
colnames(subjects.x, prefix = 'TEST')[mean.std.cols]
colnames(tidy.full)[]
colnames(tidy.full)
colnames(tidy.full)[-68]
colnames(tidy.full)[3:length(colnames(tidy.full))
]
old.column.names      <- colnames(tidy.full)[3:length(colnames(tidy.full))]
old.column.names
paste(rep('Average by Subject and Activity', length(old.column.names)), old.column.names)
## Getting and Cleaning Data
## This will take the URL provided in the assignment and download the zip file.
## It then loads and merges the two datasets, Train and Test into one dataset
## URL of the dataset
sourceDataURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
## File names for test data, train data and labels
fileList <- c('UCI HAR Dataset/test/subject_test.txt')
fileList <- append(fileList, c('UCI HAR Dataset/test/X_test.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/test/y_test.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/train/subject_train.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/train/X_train.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/train/y_train.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/activity_labels.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/features.txt'))
## Temporary File for storing the downloaded zip then extract the files we want into R
temp <- tempfile()
download.file(sourceDataURL, temp, method = "libcurl")
test.subjects   <- read.table(unz(temp, fileList[1]))
test.x          <- read.table(unz(temp, fileList[2]))
test.y          <- read.table(unz(temp, fileList[3]))
train.subjects  <- read.table(unz(temp, fileList[4]))
train.x         <- read.table(unz(temp, fileList[5]))
train.y         <- read.table(unz(temp, fileList[6]))
activities      <- read.table(unz(temp, fileList[7]))
features        <- read.table(unz(temp, fileList[8]))
unlink(temp)
## Merge testSubjects and trainSubjects into one vector, give descriptive column name
subjects              <- rbind(test.subjects, train.subjects)
subjects.x            <- rbind(test.x, train.x)
subjects.y            <- rbind(test.y, train.y)
## Rename Columns in subjects, subjects.x, subjects.y and activities
colnames(subjects)    <- 'Subject'
colnames(subjects.y)  <- 'ActivityID'
colnames(subjects.x)  <- features[, 2]
colnames(activities)  <- c('ActivityID', 'Activity')
## Get the columns with mean() or std() in their name and make one vector of them
mean.cols             <- grep('mean\\(\\)', colnames(subjects.x), ignore.case = TRUE)
std.cols              <- grep('Std\\(\\)', colnames(subjects.x), ignore.case = TRUE)
mean.std.cols         <- c(mean.cols, std.cols)
## Subset the data with the mean.std.cols vector
trim.subjects.x   <- subjects.x[, mean.std.cols]
## Name columns based on their column names from subjects.x
colnames(trim.subjects.x) <- colnames(subjects.x)[mean.std.cols]
## Merge subjects.y and activities by ActivityID, make sure to not sort the data
## or we will have the wrong activities with the wrong subjects!!!
## To do this we add an id column temporarily
subjects.y$id         <- 1:nrow(subjects.y)
tidy.subjects.y       <- merge(subjects.y, activities, by = 'ActivityID', sort = FALSE)
tidy.subjects.y       <- tidy.subjects.y[order(tidy.subjects.y$id), ]
tidy.subjects.y       <- data.frame(tidy.subjects.y[, 3])
colnames(tidy.subjects.y)[1] <- 'Activity'
## Make one big data frame
subjects.full         <- cbind(subjects, tidy.subjects.y, trim.subjects.x)
## Get the average of each datapoint for each subject and activity pair
grouping              <- list(
Subject = subjects.full$Subject
,Activity = subjects.full$Activity
)
column.count          <- length(colnames(tidy.full))
tidy.full             <- aggregate(subjects.full[, 3:column.count], grouping, mean, na.rm = TRUE)
## Give tidy column names
old.column.names      <- colnames(tidy.full)[3:length(colnames(tidy.full))]
prefix.name           <- 'Average by Subject and Activity'
new.column.names      <- paste(rep(prefix.name, length(old.column.names)), old.column.names)
colnames(tidy.full)[3:column.count] <- new.column.names
## Getting and Cleaning Data
## This will take the URL provided in the assignment and download the zip file.
## It then loads and merges the two datasets, Train and Test into one dataset
## URL of the dataset
sourceDataURL <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
## File names for test data, train data and labels
fileList <- c('UCI HAR Dataset/test/subject_test.txt')
fileList <- append(fileList, c('UCI HAR Dataset/test/X_test.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/test/y_test.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/train/subject_train.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/train/X_train.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/train/y_train.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/activity_labels.txt'))
fileList <- append(fileList, c('UCI HAR Dataset/features.txt'))
## Temporary File for storing the downloaded zip then extract the files we want into R
temp <- tempfile()
download.file(sourceDataURL, temp, method = "libcurl")
test.subjects   <- read.table(unz(temp, fileList[1]))
test.x          <- read.table(unz(temp, fileList[2]))
test.y          <- read.table(unz(temp, fileList[3]))
train.subjects  <- read.table(unz(temp, fileList[4]))
train.x         <- read.table(unz(temp, fileList[5]))
train.y         <- read.table(unz(temp, fileList[6]))
activities      <- read.table(unz(temp, fileList[7]))
features        <- read.table(unz(temp, fileList[8]))
unlink(temp)
## Merge testSubjects and trainSubjects into one vector, give descriptive column name
subjects              <- rbind(test.subjects, train.subjects)
subjects.x            <- rbind(test.x, train.x)
subjects.y            <- rbind(test.y, train.y)
## Rename Columns in subjects, subjects.x, subjects.y and activities
colnames(subjects)    <- 'Subject'
colnames(subjects.y)  <- 'ActivityID'
colnames(subjects.x)  <- features[, 2]
colnames(activities)  <- c('ActivityID', 'Activity')
## Get the columns with mean() or std() in their name and make one vector of them
mean.cols             <- grep('mean\\(\\)', colnames(subjects.x), ignore.case = TRUE)
std.cols              <- grep('Std\\(\\)', colnames(subjects.x), ignore.case = TRUE)
mean.std.cols         <- c(mean.cols, std.cols)
## Subset the data with the mean.std.cols vector
trim.subjects.x   <- subjects.x[, mean.std.cols]
## Name columns based on their column names from subjects.x
colnames(trim.subjects.x) <- colnames(subjects.x)[mean.std.cols]
## Merge subjects.y and activities by ActivityID, make sure to not sort the data
## or we will have the wrong activities with the wrong subjects!!!
## To do this we add an id column temporarily
subjects.y$id         <- 1:nrow(subjects.y)
tidy.subjects.y       <- merge(subjects.y, activities, by = 'ActivityID', sort = FALSE)
tidy.subjects.y       <- tidy.subjects.y[order(tidy.subjects.y$id), ]
tidy.subjects.y       <- data.frame(tidy.subjects.y[, 3])
colnames(tidy.subjects.y)[1] <- 'Activity'
## Make one big data frame
subjects.full         <- cbind(subjects, tidy.subjects.y, trim.subjects.x)
## Get the average of each datapoint for each subject and activity pair
grouping              <- list(
Subject = subjects.full$Subject
,Activity = subjects.full$Activity
)
column.count          <- length(colnames(subjects.full))
tidy.full             <- aggregate(subjects.full[, 3:column.count], grouping, mean, na.rm = TRUE)
## Give tidy column names
old.column.names      <- colnames(tidy.full)[3:length(colnames(tidy.full))]
prefix.name           <- 'Average by Subject and Activity'
new.column.names      <- paste(rep(prefix.name, length(old.column.names)), old.column.names)
colnames(tidy.full)[3:column.count] <- new.column.names
View(tidy.full)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
?rnorm
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
?rbinom
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
library(swirl)
swirl()
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
matrix(1:20, nrow = 4, ncol = 5 )
matrix(1:20, 4, 5)
matrix(data = 1:20, nrow = 4, ncol = 5)
my_matrix2(1:20, 4, 5)
my_matrix2 <- matrix(1:20, 4, 5)
identical(my_matrix, my_matrix2)
patients <- c('Bill', 'Gina', 'Kelly', 'Sean')
cbind(patients, my_matrix)
my_data <- ddata.class(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- c('patient', 'age', 'weight', 'bp', 'rating', 'test')
colnames(my_data) = cnames
colnames(my_data) <- cnames
my_data
TRUE == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5 != 7
!(5 == 7)
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6>4)
identical('twins', 'twins')
xor(5 ==6, !FALSE)
ints <- sample(10)
ints
ints > 5
which(ints > 7)
any(ints < 0)
all (ints > 0)
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
?n
?n_distinct
pack_sum <- summarize(by_package, count = n(), unique = n_distinct(ip_id), countries = n_distinct(country), avg_bytes = mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum$count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
exit()
bye()
acs_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
getwd()
setwd("/Users/dbucholt/Programming/R/Getting and Cleaning Data/Week4")
download.file(acs_url, 'acs.csv', method = "libcurl")
acs.data <- read.csv('acs.csv')
View(acs.data)
strsplit(colnames(acs.data),"wgtp")
tst <- colnames(acs_url)
tst
tst <- colnames(acs.data)
tst
gdp_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file (gdp_url, 'gdp.csv', method = 'libcurl')
gdp.data <- read.csv('gdp.csv')
View(gdp.data)
gdp.data <- read.csv('gdp.csv', skip = 4)
gdp.data <- read.csv('gdp.csv', skip = 4, nrows = 190)
?rep
?subs
?subst
??substring
?substring
?gsub
gdp.data[, X.4]
gdp.data[, 'X.4']
gsub(',', '', gdp.data[, 'X.4'])
gsub(',', '', gdp.data[, 'X.4']) %>% as.numeric()
gsub(',', '', gdp.data[, 'X.4']) %>% as.numeric() %>% mean()
gdp.data[, "X.3"]
grep(gdp.data[, "X.3"], ''
)
?grep
grep(^United, gdp.data[, "X.3"])
grep('^United', gdp.data[, "X.3"])
grep('^United', gdp.data[1:98, "X.3"])
grep('^[uU]nited', gdp.data[1:98, "X.3"])
grep('^[u]nited', gdp.data[1:98, "X.3"])
grep('^[uU]nited', gdp.data[1:98, "X.3"])
?read.csv
gdp.data <- read.csv('gdp.csv', skip = 4, nrows = 190, encoding = 'UTF 8')
gdp.data <- read.csv('gdp.csv', skip = 4, nrows = 190, encoding = 'UTF 16')
gdp2_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
edu_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
download.file (gdp2_url, 'fgdp.csv', method = 'libcurl')
download.file (edu_url, 'fedstats_country.csv', method = 'libcurl')
gdp2.data <- read.csv('fgdp.csv')
edu.data <- read.csv('fedstats_country.csv')
View(gdp2.data)
View(gdp2.data, skip = 4, nrows = 190)
gdp2.data <- read.csv('fgdp.csv', nrows = 190, skip = 4)
View(edu.data)
library(dplyr)
?dplyr
merge(gdp2.data, edu.data, by.x = X, by.y = CountryCode)
merge(gdp2.data, edu.data, by.x = 'X', by.y = CountryCode)
merge(gdp2.data, edu.data, by.x = 'X', by.y = 'CountryCode')
merged <- merge(gdp2.data, edu.data, by.x = 'X', by.y = 'CountryCode')
View((merged))
grep('^Fiscal year end:*', merged$Special.Notes)
year.end <- merged[, grep('^Fiscal year end:*', merged$Special.Notes)]
year.end <- merged[grep('^Fiscal year end:*', merged$Special.Notes), ]
year.end
year.end <- merged[grep('^Fiscal year end:*', merged$Special.Notes), "Special.Notes"]
year.end
year.end <- merged[grep('^Fiscal year end:*June*', merged$Special.Notes), "Special.Notes"]
year.end
year.end <- merged[grep('^Fiscal year end:*June*', merged$Special.Notes), "Special.Notes"]
year.end
year.end <- merged[grep('^Fiscal year end:*', merged$Special.Notes), "Special.Notes"]
year.end
year.end <- merged[grep('^Fiscal year end:*?June*', merged$Special.Notes), "Special.Notes"]
year.end
grep('^Fiscal year end:*?June*', merged$Special.Notes)
grep('^Fiscal year end: June*', merged$Special.Notes)
year.end <- merged[grep('^Fiscal year end: June*', merged$Special.Notes), "Special.Notes"]
year.end
year.end <- merged[grep('^Fiscal year end\: June*', merged$Special.Notes), "Special.Notes"]
year.end <- merged[grep('^Fiscal year end/: June*', merged$Special.Notes), "Special.Notes"]
year.end
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
head(sampleTimes)
sample.dates <- as.date(sampleTimes, %Y%D%M)
sample.dates <- as.date(sampleTimes, '%Y%D%M')
sample.dates <- as.Date(sampleTimes, '%Y%D%M')
sampleTimes
sample.dates <- as.Date(sampleTimes, '%Y%M%D')
sample.dates
class(sampleTimes)
weekdays(sampleTimes)
weekdays(sampleTimes) == "Monday"
sample.monday <- weekdays(sampleTimes) == "Monday"
year(sampleTimes)
years(sampleTimes)
?year
years(sampleTimes)
??year
library(lubridate)
install.packages(lubridate)
install.packages('lubridate')
library(lubridate)
year(sampleTimes)
sample.years <- year(sampleTimes) == "2012"
sum(sampleTimes[sample.years])
sum(sample.years)
sum(identical(sample.years, sample.monday))
sample.years & sample.monday
sample.monday.2012 <- sample.years & sample.monday
sum(sample.monday.2012)
strsplit('wgtp', gdp.data)
strsplit('wgtp', colnames(gdp.data))
colnames(gdp.data)
strsplit('wgtp', colnames(acs.data))
acs.data
colnames(acs.data)
strsplit('wgtp', colnames(acs.data))
?strsplit
strsplit(colnames(acs.data), 'wgtp')
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, c('sex', 'class'))
submit()
students3
?gather
submit()
submit()
submit()
submit()
?spread()
?spread
submit()
submit()
submit()
submit()
submit()
submit()
submit()
View(students3)
submit()
extract_numeric("class5")
submit()
students4
submit()
?unique
submit()
submit()
passed
failed
passed <- mutate(passed, status = 'passed')
failed <- mutate(failed, status = 'failed')
bind_rows(passed, failed)
sat
contains( 'this','total')
?contains
?select
View(sat)
submit()
submit()
submit()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
minute(this_moment)
my_date ymd('1989-05-17')
my_date <- ymd('1989-05-17')
my_data
my_date
class(my_date)
ymd("1989 may 17")
ymd("1989 May 17")
mdy("March 12, 1975")
mdy(25081985)
dmy(25081985)
ymd("192012")
ymd("1920-1/2")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 0, minutes = 7)
this_moment
now('America/New_York')
nyc <- now('America/New_York')
nyc
depart <- nyc + days(2)
depart
depart <- update(hours = 17, minutes = 34)
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
